{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "def preproccess_data(str):\n",
    "    X_data=[]\n",
    "    Y_data=[]\n",
    "    #read and split dataset\n",
    "    with open(str) as f:\n",
    "        for line in f:\n",
    "            l=line.split(\":\")\n",
    "            Y_data.append(l[0])\n",
    "            X_data.append(l[1].replace(\"?\\n\",\"\").strip())\n",
    "    return X_data,Y_data\n",
    "\n",
    "def encode_Y(y_data):\n",
    "    #unique in Y_data\n",
    "    uset=set()\n",
    "    for i in y_data:\n",
    "        uset.add(i)\n",
    "    Y_class=list(uset)\n",
    "\n",
    "    #encode Y_data to Y_encode\n",
    "    Y_encode=[]\n",
    "    for i in range(len(y_data)):\n",
    "        temp=y_data[i]\n",
    "        if temp in Y_class:\n",
    "            Y_encode.append(Y_class.index(temp))\n",
    "    #print(Y_encode)\n",
    "    return Y_encode,Y_class\n",
    "\n",
    "#train_path=\"../textmining/set3000.txt\"\n",
    "train_path=\"../textmining/set5500.txt\"\n",
    "X_data,Y_data=preproccess_data(train_path)\n",
    "Y_encode,Y_class=encode_Y(Y_data)\n",
    "\n",
    "#encode X_data with CountVectorizer\n",
    "count_vect=CountVectorizer()\n",
    "X_encode=count_vect.fit_transform(X_data).toarray()\n",
    "\n",
    "#encode X_data with TfidfTransformer\n",
    "tfidf_transformer= TfidfTransformer()\n",
    "tfidf_transformer.fit(X_encode)\n",
    "count_vector=count_vect.transform(X_data)\n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)\n",
    "X_encode=tf_idf_vector\n",
    "\n",
    "#split train vs test set\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X_encode,Y_encode,test_size=0.4,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9747781410555815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HUM       1.00      0.93      0.96        43\n",
      "        ENTY       1.00      1.00      1.00       451\n",
      "         NUM       0.91      0.99      0.95       488\n",
      "        DESC       1.00      1.00      1.00       455\n",
      "        ABBR       0.98      0.92      0.95       342\n",
      "         LOC       1.00      0.95      0.97       362\n",
      "\n",
      "    accuracy                           0.97      2141\n",
      "   macro avg       0.98      0.96      0.97      2141\n",
      "weighted avg       0.98      0.97      0.97      2141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#classifier with SVM\n",
    "cls=svm.SVC(C=3)\n",
    "cls.fit(X_train,Y_train)\n",
    "Y_predict=cls.predict(X_test)\n",
    "Y_predict_decode=[Y_class[i] for i in Y_predict]\n",
    "#compute accuracy\n",
    "print(\"Accuracy:\",cls.score(X_test,Y_test))\n",
    "\n",
    "#compute F1,recall,precission\n",
    "Y_test_decode=[Y_class[i] for i in Y_test]\n",
    "labels=Y_class\n",
    "print(metrics.classification_report(Y_test_decode,Y_predict_decode,target_names=labels))\n",
    "#cm= metrics.confusion_matrix(y_pred=Y_predict_decode,y_true=Y_test_decode,labels=labels)\n",
    "#print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "#test_path=\"../textmining/test3000.txt\"\n",
    "test_path=\"../textmining/test5500.txt\"\n",
    "X_test_data,Y_test_data=preproccess_data(test_path)\n",
    "test_count_vector=count_vect.transform(X_test_data)\n",
    "tf_idf_vector=tfidf_transformer.transform(test_count_vector)\n",
    "X_test_encode=tf_idf_vector\n",
    "Y_test_predict=cls.predict(X_test_encode)\n",
    "\n",
    "Y_test_encode,Y_test_class=encode_Y(Y_test_data)\n",
    "#compute accuracy in Test set\n",
    "print(\"Accuracy:\",cls.score(X_test_encode,Y_test_encode))\n",
    "\n",
    "\n",
    "#Y_test_pred_decode=[Y_class[i] for i in Y_test_predict]\n",
    "#print(Y_test_pred_decode)\n",
    "#print(Y_test_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "485035c5b2a6f2b50dc2dc5ca51aeeb931032fbc9adc2e30c7c528d6bf8a9176"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
