{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis-Dense.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyDGL3gwwoeh",
        "outputId": "5c2467f0-f910-4a7b-d2e9-064e4b445a9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8iHUzC6w6Ej",
        "outputId": "c980769d-9a4d-473b-a9b4-413fc7bf5b7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip \"/content/drive/My Drive/SyncPC/Deep learning/IMDB Dataset.csv.zip\" "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/SyncPC/Deep learning/IMDB Dataset.csv.zip\n",
            "  inflating: IMDB Dataset.csv        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XspkSNSCxFJ-"
      },
      "source": [
        "import pandas as pd\n",
        "data_pd = pd.read_csv(\"IMDB Dataset.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqAzdVknxVuJ"
      },
      "source": [
        "#Using bag of word vectors\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=200)#,ngram_range=(1,2),stop_words=[\"the\",\"that\"])\n",
        "X = vectorizer.fit_transform(data_pd[\"review\"].values)\n",
        "X = X.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gBuKE8XxqC1"
      },
      "source": [
        "data_pd[\"label\"] = data_pd[\"sentiment\"].map({'positive': 1, 'negative': 0})\n",
        "data_pd.head()\n",
        "y = data_pd[\"label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud7AT4Pixt58",
        "outputId": "82d06209-3ca2-424c-a404-dd5562dea3a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, stratify=y)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "\n",
        "\n",
        "print (X_train.shape,X_test.shape, X_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 200) (25000, 200) (5000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB1VV_pRx5yH",
        "outputId": "a84eafdb-dd7a-4188-8cb1-a9dcb9e6e812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(200,))\n",
        "dense_layer1 = Dense(100) (input_layer)\n",
        "dense_layer2= Dense(10, activation=\"tanh\")(dense_layer1)\n",
        "dense_layer = Dense(1, activation=\"sigmoid\")(dense_layer2)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=dense_layer)\n",
        "model.compile(loss='binary_crossentropy', optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "mc = ModelCheckpoint(\"best_checkpoint.h5\", monitor=\"val_accuracy\" , save_best_only=True, save_weights_only=True)\n",
        "\n",
        "model.fit(X_train,y_train,validation_data=(X_val,y_val), epochs= 20, batch_size=20, callbacks=[mc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 989/1000 [============================>.] - ETA: 0s - loss: 0.5375 - accuracy: 0.7329WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.7336 - val_loss: 0.5055 - val_accuracy: 0.7498\n",
            "Epoch 2/20\n",
            " 986/1000 [============================>.] - ETA: 0s - loss: 0.4982 - accuracy: 0.7576WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4981 - accuracy: 0.7577 - val_loss: 0.5029 - val_accuracy: 0.7568\n",
            "Epoch 3/20\n",
            " 991/1000 [============================>.] - ETA: 0s - loss: 0.4880 - accuracy: 0.7664WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4877 - accuracy: 0.7667 - val_loss: 0.5014 - val_accuracy: 0.7636\n",
            "Epoch 4/20\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.4818 - accuracy: 0.7658WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4822 - accuracy: 0.7656 - val_loss: 0.5054 - val_accuracy: 0.7546\n",
            "Epoch 5/20\n",
            " 986/1000 [============================>.] - ETA: 0s - loss: 0.4798 - accuracy: 0.7681WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4795 - accuracy: 0.7685 - val_loss: 0.5053 - val_accuracy: 0.7598\n",
            "Epoch 6/20\n",
            " 978/1000 [============================>.] - ETA: 0s - loss: 0.4725 - accuracy: 0.7746WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4727 - accuracy: 0.7739 - val_loss: 0.4971 - val_accuracy: 0.7594\n",
            "Epoch 7/20\n",
            " 994/1000 [============================>.] - ETA: 0s - loss: 0.4702 - accuracy: 0.7763WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4700 - accuracy: 0.7763 - val_loss: 0.5063 - val_accuracy: 0.7564\n",
            "Epoch 8/20\n",
            " 995/1000 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.7785WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4659 - accuracy: 0.7785 - val_loss: 0.5017 - val_accuracy: 0.7546\n",
            "Epoch 9/20\n",
            " 995/1000 [============================>.] - ETA: 0s - loss: 0.4637 - accuracy: 0.7814WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4637 - accuracy: 0.7814 - val_loss: 0.5009 - val_accuracy: 0.7630\n",
            "Epoch 10/20\n",
            " 999/1000 [============================>.] - ETA: 0s - loss: 0.4610 - accuracy: 0.7832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4612 - accuracy: 0.7831 - val_loss: 0.5040 - val_accuracy: 0.7504\n",
            "Epoch 11/20\n",
            " 994/1000 [============================>.] - ETA: 0s - loss: 0.4566 - accuracy: 0.7837WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4567 - accuracy: 0.7836 - val_loss: 0.5075 - val_accuracy: 0.7508\n",
            "Epoch 12/20\n",
            " 997/1000 [============================>.] - ETA: 0s - loss: 0.4550 - accuracy: 0.7861WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4552 - accuracy: 0.7858 - val_loss: 0.5030 - val_accuracy: 0.7518\n",
            "Epoch 13/20\n",
            " 994/1000 [============================>.] - ETA: 0s - loss: 0.4511 - accuracy: 0.7887WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4511 - accuracy: 0.7886 - val_loss: 0.5095 - val_accuracy: 0.7522\n",
            "Epoch 14/20\n",
            " 973/1000 [============================>.] - ETA: 0s - loss: 0.4497 - accuracy: 0.7879WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4494 - accuracy: 0.7880 - val_loss: 0.5196 - val_accuracy: 0.7538\n",
            "Epoch 15/20\n",
            " 975/1000 [============================>.] - ETA: 0s - loss: 0.4485 - accuracy: 0.7899WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4485 - accuracy: 0.7900 - val_loss: 0.5180 - val_accuracy: 0.7496\n",
            "Epoch 16/20\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 0.4460 - accuracy: 0.7889WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4457 - accuracy: 0.7890 - val_loss: 0.5118 - val_accuracy: 0.7554\n",
            "Epoch 17/20\n",
            " 990/1000 [============================>.] - ETA: 0s - loss: 0.4408 - accuracy: 0.7972WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4408 - accuracy: 0.7975 - val_loss: 0.5160 - val_accuracy: 0.7530\n",
            "Epoch 18/20\n",
            " 984/1000 [============================>.] - ETA: 0s - loss: 0.4409 - accuracy: 0.7937WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4405 - accuracy: 0.7940 - val_loss: 0.5276 - val_accuracy: 0.7444\n",
            "Epoch 19/20\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.4402 - accuracy: 0.7953WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4401 - accuracy: 0.7954 - val_loss: 0.5368 - val_accuracy: 0.7426\n",
            "Epoch 20/20\n",
            " 961/1000 [===========================>..] - ETA: 0s - loss: 0.4385 - accuracy: 0.7953WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 0.4389 - accuracy: 0.7951 - val_loss: 0.5203 - val_accuracy: 0.7458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f44e1adf208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrfLLnvB1eLL"
      },
      "source": [
        "model.load_weights(\"best_checkpoint.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMR5vH9B1jjM"
      },
      "source": [
        "y_test_pred = model.predict(X_test)\n",
        "y_test_pred = [1 if pred > 0.5 else 0 for pred in y_test_pred ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mps8M9hv1wvA",
        "outputId": "e2a78544-14dc-439e-808b-12e242e76344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "print(\"Acc:\",(1 - np.sum(np.abs(y_test_pred- y_test))/len(y_test_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.76032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape=(200,))\n",
        "dense_layer1 = Dense(100, activation=\"sigmoid\")(input_layer)\n",
        "dense_layer2= Dense(50, activation=\"tanh\")(dense_layer1)\n",
        "dense_layer3= Dense(10, activation=\"tanh\")(dense_layer2)\n",
        "dense_layer = Dense(1, activation=\"sigmoid\")(dense_layer3) \n",
        "\n",
        "model = Model(inputs=input_layer, outputs=dense_layer)\n"
      ],
      "metadata": {
        "id": "BHRfu6nJZq7M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}